---
title: "PCA_tSNE_UMAP"
author: "Jim Costello"
date: "7/15/2024"
output: html_document

---


#### Contents:

* [Prepare the data](#data)
* [PCA: Principal Component Analysis](#pca)
* [tSNE: t-distributed stochastic neighbor embedding](#tsne)
* [UMAP: Uniform Manifold Approximation and Projection](#umap)
* [Hierarchical Clustering](#hclust)
* [Report session information](#session)


### Load necessary packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# if you need to install packages, use the following
#install.packages("umap")
#install.packages("rlang")
#install.packages("ggplot2")

library(ggplot2)
library(ggfortify)
library(Rtsne)
library(umap)
library(limma)
library(RCurl)
library(factoextra)
library(cluster)

# set the working directory to get access to the input files

```

<a name="data"/>

### Load Metabolomics data and clinial information

The data we will use were collected from individuals with and without Down sydrome. The samples are from blood plasma 
and metabolomics data were generated for each individual.



```{r, message=F}
# we will use the iris dataset as an illustrative example
data("iris")
iris <- unique(iris) # remove duplicates
iris.mat <- as.matrix(iris[,1:4])
dim(iris)
colnames(iris)

# read in the raw metabolomics data
x <- getURL("https://raw.githubusercontent.com/DS3-2024/Visualize_Cluster_HTP/main/data/P4C_LCMS_abundance_wide_011722.csv")
mets <- read.csv(text = x, row.names = 1, header = T)
dim(mets)
row.names(mets)
colnames(mets)

#read in the metadata
x <- getURL("https://raw.githubusercontent.com/DS3-2024/Visualize_Cluster_HTP/main/data/P4C_metadata_011722.csv")
info <- read.csv(text = x, row.names = 1, header = T)
dim(info)
colnames(info)

# make sure the patient order matches in both the meta data and the metabolimcs data
patients <- intersect(row.names(mets), row.names(info))
length(patients)
mets <- mets[patients,]
info <- info[patients,]
mets <- mets[order(info$Karyotype),]
info <- info[order(info$Karyotype),]

# remove the batch effect of sample source where the samples were collected
mets <- 2^t((removeBatchEffect(t(log2(mets)), batch=info$Sample_source)))


info$order <- seq(1,nrow(info))
info$Karyotype <- as.factor(info$Karyotype)
mets.info <- cbind(log2(mets), info)
```

![Sepal vs. Petal](https://plantid.net/Classic/Glossary/Sepal_files/image001.png)

<a name="pca"/>

### Principal Component Analysis
We will use PCA to plot the data and explore sample information. The examples used here is taken from Statquest. Please refer to the [PCA video](https://www.youtube.com/watch?v=FgakZw6K1QQ).

We will also be using this image to illustrate the regression line fit ![regression fit](https://miro.medium.com/v2/resize:fit:1400/1*XGaA7KWUlhWZLIezYEBIHA.gif)



```{r, message=F}

# 1D
ids <- grep("T21",mets.info$Karyotype)
plot(mets.info$Prostaglandin.A2.B2.J2[ids],rep(0,length(mets.info$Prostaglandin.A2.B2.J2[ids])), pch=20, ylab="", xlab="Prostaglandin.A2.B2.J2 expression", cex=1, col="lightseagreen")
ids <- grep("Control",mets.info$Karyotype)
points(mets.info$Prostaglandin.A2.B2.J2[ids],rep(0.05,length(mets.info$Prostaglandin.A2.B2.J2[ids])), pch=20, col="salmon", cex=1)
legend(10, 1,  fill=c("lightseagreen", "salmon"), legend=c("T21", "Control"))

ggplot(mets.info, aes(x=Karyotype, y=Prostaglandin.A2.B2.J2, fill=Karyotype)) + geom_boxplot() + geom_jitter() + theme_bw()

# 2D
ggplot(mets.info, aes(x=Hypoxanthine, y=Prostaglandin.A2.B2.J2, color=Karyotype)) + geom_point()  + theme_bw()

# lets look at a simplified example
Met1 <- c(10,11,8,3,1,3)
Met2 <- c(5,4,5,3,3,1)
plot(Met1, Met2, pch =19)

# find the mean of M1 and M2
plot(Met1, Met2, pch =19)
points(mean(Met1), mean(Met2), col="purple", pch=19, cex=3)  

# center the data and plot
Met1 = Met1 - mean(Met1)
Met2 = Met2 - mean(Met2)
plot(Met1, Met2, pch =19)
segments(0,-10,0,20, col="grey", lty=2)
segments(-10,0,20,0, col="grey", lty=2)

# add a regression line
plot(Met1, Met2, pch =19)
segments(0,-10,0,20, col="grey", lty=2)
segments(-10,0,20,0, col="grey", lty=2)
abline(lm(Met2~Met1))
segments(0,0,4,0, col="red", lwd=2)
segments(4,1,4,0, col="red", lwd=2)


# back to the HTP data
# find the mean of the X and Y directions
ggplot(mets.info, aes(x=Hypoxanthine, y=Prostaglandin.A2.B2.J2)) + geom_point()  + theme_bw() +
   geom_point(aes(x=mean(mets.info$Hypoxanthine),y=mean(mets.info$Prostaglandin.A2.B2.J2)), colour="purple", size=5)

# center the data and plot
mets.info$Hypoxanthine.standard <- mets.info$Hypoxanthine - mean(mets.info$Hypoxanthine)
mets.info$Prostaglandin.A2.B2.J2.standard <- mets.info$Prostaglandin.A2.B2.J2 - mean(mets.info$Prostaglandin.A2.B2.J2)
ggplot(mets.info, aes(x=Hypoxanthine.standard, y=Prostaglandin.A2.B2.J2.standard)) + geom_point()  + theme_bw()

# add a regression line
ggplot(mets.info, aes(x=Hypoxanthine.standard, y=Prostaglandin.A2.B2.J2.standard)) + geom_point()  + theme_bw() + geom_smooth(method='lm',se=F) + geom_point(aes(x=0,y=0), colour="red")

# note in the prcomp implementation of PCA, 
# x = PCs
# rotation = loadings
# sdev^2 = eigenvalues

#Iris data
pca <- prcomp(na.omit(iris.mat), scale=T)
autoplot(pca, data=iris, col='Species')
pca$rotation #display the loadings (named rotation in the prcomp data structure)
get_eigenvalue(pca)
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

#HTP data
pca <- prcomp(na.omit(mets), scale=T)

autoplot(pca, data=info, col='Karyotype')
autoplot(pca, data=info, col='Sample_source')

# remove outlier samples
hist(pca$x[,1], main ="PC1")
sort(pca$x[,1])
row.names(mets)[pca$x[,1] > 15]
mets <- mets[pca$x[,1] < 15,]
info <- info[pca$x[,1] < 15,]
mets.info <- cbind(mets, info)
dim(mets)
pca <- prcomp(na.omit(mets), scale=T)
autoplot(pca, data=info, col='Karyotype')
autoplot(pca, data=info, col='Sample_source')
autoplot(pca, data=info, col='Age_at_visit')

 # scree plot
var_explained = cbind(PC=seq(1, length(pca$sdev)), var=100*(pca$sdev^2 / sum(pca$sdev^2)))
ggplot(var_explained, aes(x=PC, y=var)) + geom_line() + xlab("Principal Component") + theme_bw() +
  ylab("Variance Explained (%)") + ggtitle("Scree Plot") + xlim(1,20)
```
<a name="tsne"/>

### t-distributed stochastic neighbor embedding
We will use tSNE to plot the data and explore sample information



```{r, message=F}
# tSNE is stochastic so it will produce different results based on the random seed. To get the same results, you will need to fix the seed
set.seed(48673)

# theta is parameter that balances speed and accuracy. theta=0 is the exact tSNE calculation
# perplexity is the value that balances density of the cluster size

#Iris data
tsne <- Rtsne(iris.mat, pca=F, verbose=T, perplexity=30, theta=0)
iris.info.tsne <- cbind(tsne$Y, iris)
colnames(iris.info.tsne)[1] <- "tsne1"
colnames(iris.info.tsne)[2] <- "tsne2"

ggplot(iris.info.tsne, aes(x=tsne1, y=tsne2, color=Species)) + geom_point()  + theme_bw()   


#HTP data
tsne <- Rtsne(mets, pca=F, verbose=T, perplexity=30, theta=0)
mets.info.tsne <- cbind(tsne$Y, mets.info)
colnames(mets.info.tsne)[1] <- "tsne1"
colnames(mets.info.tsne)[2] <- "tsne2"

ggplot(mets.info.tsne, aes(x=tsne1, y=tsne2, color=Karyotype)) + geom_point()  + theme_bw()   
ggplot(mets.info.tsne, aes(x=tsne1, y=tsne2, color=Sex)) + geom_point()  + theme_bw()   
ggplot(mets.info.tsne, aes(x=tsne1, y=tsne2, color=Sample_source)) + geom_point()  + theme_bw()   

# playing with perplexity
tsne <- Rtsne(mets, pca=F, verbose=T, perplexity=5, theta=0)
mets.info.tsne <- cbind(tsne$Y, mets.info)
colnames(mets.info.tsne)[1] <- "tsne1"
colnames(mets.info.tsne)[2] <- "tsne2"
ggplot(mets.info.tsne, aes(x=tsne1, y=tsne2, color=Karyotype)) + geom_point()  + theme_bw()   

tsne <- Rtsne(mets, pca=F, verbose=T, perplexity=100, theta=0)
mets.info.tsne <- cbind(tsne$Y, mets.info)
colnames(mets.info.tsne)[1] <- "tsne1"
colnames(mets.info.tsne)[2] <- "tsne2"
ggplot(mets.info.tsne, aes(x=tsne1, y=tsne2, color=Karyotype)) + geom_point()  + theme_bw()   
```

<a name="umap"/>

### UMAP: Uniform Manifold Approximation and Projection
We will use UMAP to plot the data and explore sample information. Bookmark the [Statquest video](https://www.youtube.com/watch?v=eN0wFzBA4Sc) on UMAP to review again and again in the future. 



```{r, message=F}
#Iris data
u <- umap(iris.mat)
iris.info.umap <- cbind(u$layout, iris)
colnames(iris.info.umap)[1] <- "UMAP1"
colnames(iris.info.umap)[2] <- "UMAP2"

ggplot(iris.info.umap, aes(x=UMAP1, y=UMAP2, color=Species)) + geom_point()  + theme_bw()   


#HTP data
u <- umap(mets)
mets.info.umap <- cbind(u$layout, mets.info)
colnames(mets.info.umap)[1] <- "UMAP1"
colnames(mets.info.umap)[2] <- "UMAP2"

ggplot(mets.info.umap, aes(x=UMAP1, y=UMAP2, color=Karyotype)) + geom_point()  + theme_bw()   

# to explore the parameters in UMAP, you can see the default values and adjust in the function
umap.defaults

u <- umap(mets, n_neighbors=5)
mets.info.umap <- cbind(u$layout, mets.info)
colnames(mets.info.umap)[1] <- "UMAP1"
colnames(mets.info.umap)[2] <- "UMAP2"

ggplot(mets.info.umap, aes(x=UMAP1, y=UMAP2, color=Karyotype)) + geom_point()  + theme_bw()   


```

<a name="hclust"/>

### Hierarchical Clustering

Note: Make sure you install the `hclust` package in R. Some of the code is taken from this nice [tutorial post](https://bradleyboehmke.github.io/HOML/hierarchical.html) on hierarchical clustering. 

```{r, message = F, warning = F}

# we will first perform agglomerative hierachical clustering (bottom up) using the agnes function in the cluster package

# test the various linkage methods to see which provides the strongest clusters
#define linkage methods
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

#function to compute agglomerative coefficient
ac <- function(x) {
  agnes(scale(mets), method = x)$ac
}

#calculate agglomerative coefficient for each clustering linkage method
sapply(m, ac)

#generate the agglomerative clustering and perform some visualizations
ac <- agnes(scale(mets), method="ward")
plot(as.hclust(ac), cex=0.3, main="Dendrogram for AGNES")
rect.hclust(ac, k = 4, border = 2:5)

# lets see how we can determine the appropriate cluster size

# The total within-cluster sum of square (wss) measures the compactness of the clustering and we want it to be as small as possible. 
p1 <- fviz_nbclust(scale(mets), FUN = hcut, method = "wss", 
                   k.max = 10) +
  ggtitle("(A) Elbow method")
# silhouette method determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering.
p2 <- fviz_nbclust(scale(mets), FUN = hcut, method = "silhouette", 
                   k.max = 10) +
  ggtitle("(B) Silhouette method")
# The gap statistic compares the total intracluster variation for different values of k with their expected values under null reference distribution of the data (i.e. a distribution with no obvious clustering). The reference dataset is generated using Monte Carlo simulations of the sampling process.
p3 <- fviz_nbclust(scale(mets), FUN = hcut, method = "gap_stat", 
                   k.max = 10) +
  ggtitle("(C) Gap statistic")
gridExtra::grid.arrange(p1, p2, p3, nrow = 1)


# lets see where the clusters fall in PCA space
mets.info$agnesclusters <- as.factor(cutree(ac, k=5))
autoplot(pca, data=mets.info, col='agnesclusters')


# we will next perform divisive hierarchical clustering (top down) using the diana function in the cluster package
di <- diana(scale(mets))
di$dc
plot(as.hclust(di), cex=0.3, main="Dendrogram for DIANA")

mets.info$dianaclusters <- as.factor(cutree(di, k=5))
autoplot(pca, data=mets.info, col='dianaclusters')


```



<a name="session"/>

### Session Information

```{r, message = F}
sessionInfo()
```

